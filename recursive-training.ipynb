{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-10T10:39:40.861357Z",
     "iopub.status.busy": "2020-10-10T10:39:40.860674Z",
     "iopub.status.idle": "2020-10-10T10:39:42.622774Z",
     "shell.execute_reply": "2020-10-10T10:39:42.621930Z"
    },
    "papermill": {
     "duration": 1.791941,
     "end_time": "2020-10-10T10:39:42.622899",
     "exception": false,
     "start_time": "2020-10-10T10:39:40.830958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import psutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-10-10T10:39:42.651498Z",
     "iopub.status.busy": "2020-10-10T10:39:42.650765Z",
     "iopub.status.idle": "2020-10-10T10:40:17.791692Z",
     "shell.execute_reply": "2020-10-10T10:40:17.792185Z"
    },
    "papermill": {
     "duration": 35.162943,
     "end_time": "2020-10-10T10:40:17.792351",
     "exception": false,
     "start_time": "2020-10-10T10:39:42.629408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001', '002', '003', '004', '005', '006', '007', '008', '009', '010', '011', '012', '013', '014', '015', '016', '017', '018', '019', '020', '021', '022', '023', '024', '025', '026', '027', '028', '029', '030', '031', '032', '033', '034', '035', '036', '037', '038', '039', '040', '041', '042', '043', '044', '045', '046', '047', '048', '049', '050', '051', '052', '053', '054', '055', '056', '057', '058', '059', '060', '061', '062', '063', '064', '065', '066', '067', '068', '069', '070', '071', '072', '073', '074', '075', '076', '077', '078', '079', '080', '081', '082', '083', '084', '085', '086', '087', '088', '089', '090', '091', '092', '093', '094', '095', '096', '097', '098', '099', '100']\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../input/age-predict/train'\n",
    "def load_split_train_test(datadir, valid_size = .1):\n",
    "    train_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                           transforms.RandomCrop([196, 196]),\n",
    "                                           transforms.RandomHorizontalFlip(),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
    "                                          ])\n",
    "    test_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
    "                                         ])\n",
    "    train_data = datasets.ImageFolder(datadir, transform=train_transforms)\n",
    "    test_data = datasets.ImageFolder(datadir, transform=test_transforms)    \n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data,\n",
    "                   sampler=train_sampler, batch_size=64)\n",
    "    testloader = torch.utils.data.DataLoader(test_data,\n",
    "                   sampler=test_sampler, batch_size=64)\n",
    "    return trainloader, testloader\n",
    "trainloader, testloader = load_split_train_test(data_dir, .2)\n",
    "print(trainloader.dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-10T10:40:18.162125Z",
     "iopub.status.busy": "2020-10-10T10:40:18.161197Z",
     "iopub.status.idle": "2020-10-10T10:40:24.298722Z",
     "shell.execute_reply": "2020-10-10T10:40:24.298088Z"
    },
    "papermill": {
     "duration": 6.499843,
     "end_time": "2020-10-10T10:40:24.298862",
     "exception": false,
     "start_time": "2020-10-10T10:40:17.799019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                                  else \"cpu\")\n",
    "model = torch.load('../input/recursive-training/aerialmodel.pth')\n",
    "#model = models.resnet18(pretrained=True)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-10T10:40:24.323343Z",
     "iopub.status.busy": "2020-10-10T10:40:24.322608Z",
     "iopub.status.idle": "2020-10-10T10:40:24.334065Z",
     "shell.execute_reply": "2020-10-10T10:40:24.333425Z"
    },
    "papermill": {
     "duration": 0.027104,
     "end_time": "2020-10-10T10:40:24.334182",
     "exception": false,
     "start_time": "2020-10-10T10:40:24.307078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "#model.fc = nn.Sequential(nn.Linear(512, 128),\n",
    "#                         nn.ReLU(),\n",
    "#                         nn.Dropout(0.2),\n",
    "#                         nn.Linear(128, 1))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0000005)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-10T10:40:24.360195Z",
     "iopub.status.busy": "2020-10-10T10:40:24.358566Z",
     "iopub.status.idle": "2020-10-10T10:40:24.360865Z",
     "shell.execute_reply": "2020-10-10T10:40:24.361331Z"
    },
    "papermill": {
     "duration": 0.019534,
     "end_time": "2020-10-10T10:40:24.361438",
     "exception": false,
     "start_time": "2020-10-10T10:40:24.341904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def forward_model_train(inputs, labels):\n",
    "    inputs, labels = inputs.to(device), labels.to(device).type(torch.float32)\n",
    "    #sceduler\n",
    "    optimizer.zero_grad()\n",
    "    #scheduler.step()\n",
    "    logps = torch.flatten(model.forward(inputs))\n",
    "    loss = criterion(logps, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "def forward_model_val(inputs, labels):\n",
    "    inputs, labels = inputs.to(device), labels.to(device).type(torch.float32)\n",
    "    logps = torch.flatten(model.forward(inputs))\n",
    "    batch_loss = criterion(logps, labels)\n",
    "    return batch_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-10T10:40:24.385813Z",
     "iopub.status.busy": "2020-10-10T10:40:24.385028Z",
     "iopub.status.idle": "2020-10-10T13:46:14.941596Z",
     "shell.execute_reply": "2020-10-10T13:46:14.942983Z"
    },
    "papermill": {
     "duration": 11150.574645,
     "end_time": "2020-10-10T13:46:14.943252",
     "exception": false,
     "start_time": "2020-10-10T10:40:24.368607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5e-07]\n",
      "[5e-09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1.. Train loss: 58.050.. Test loss: 54.188.. \n",
      "Epoch 1/1.. Train loss: 56.663.. Test loss: 55.998.. \n",
      "Epoch 1/1.. Train loss: 55.349.. Test loss: 54.914.. \n",
      "Epoch 1/1.. Train loss: 55.764.. Test loss: 54.958.. \n",
      "Epoch 1/1.. Train loss: 60.649.. Test loss: 55.165.. \n",
      "Epoch 1/1.. Train loss: 57.000.. Test loss: 54.441.. \n",
      "Epoch 1/1.. Train loss: 56.889.. Test loss: 56.074.. \n",
      "Epoch 1/1.. Train loss: 57.231.. Test loss: 55.204.. \n",
      "Epoch 1/1.. Train loss: 57.427.. Test loss: 54.401.. \n",
      "Epoch 1/1.. Train loss: 57.763.. Test loss: 54.682.. \n",
      "Epoch 1/1.. Train loss: 58.595.. Test loss: 55.123.. \n",
      "Epoch 1/1.. Train loss: 58.904.. Test loss: 54.605.. \n",
      "Epoch 1/1.. Train loss: 56.146.. Test loss: 55.701.. \n",
      "Epoch 1/1.. Train loss: 59.642.. Test loss: 54.561.. \n",
      "Epoch 1/1.. Train loss: 59.368.. Test loss: 55.695.. \n",
      "Epoch 1/1.. Train loss: 56.983.. Test loss: 54.565.. \n",
      "Epoch 1/1.. Train loss: 58.067.. Test loss: 56.066.. \n",
      "Epoch 1/1.. Train loss: 57.926.. Test loss: 55.781.. \n",
      "Epoch 1/1.. Train loss: 61.587.. Test loss: 54.147.. \n",
      "Epoch 1/1.. Train loss: 56.671.. Test loss: 55.601.. \n",
      "Epoch 1/1.. Train loss: 56.019.. Test loss: 55.002.. \n",
      "Epoch 1/1.. Train loss: 55.498.. Test loss: 54.166.. \n",
      "Epoch 1/1.. Train loss: 57.068.. Test loss: 56.293.. \n",
      "Epoch 1/1.. Train loss: 55.137.. Test loss: 55.128.. \n",
      "Epoch 1/1.. Train loss: 57.925.. Test loss: 55.042.. \n",
      "Epoch 1/1.. Train loss: 54.525.. Test loss: 54.409.. \n",
      "Epoch 1/1.. Train loss: 57.070.. Test loss: 55.427.. \n",
      "Epoch 1/1.. Train loss: 54.656.. Test loss: 54.403.. \n",
      "Epoch 1/1.. Train loss: 56.246.. Test loss: 54.789.. \n",
      "Epoch 1/1.. Train loss: 59.397.. Test loss: 55.849.. \n",
      "Epoch 1/1.. Train loss: 59.000.. Test loss: 54.485.. \n",
      "Epoch 1/1.. Train loss: 55.328.. Test loss: 55.459.. \n",
      "Epoch 1/1.. Train loss: 57.659.. Test loss: 55.061.. \n",
      "Epoch 1/1.. Train loss: 54.384.. Test loss: 54.707.. \n",
      "Epoch 1/1.. Train loss: 58.180.. Test loss: 55.862.. \n",
      "Epoch 1/1.. Train loss: 57.715.. Test loss: 54.872.. \n",
      "Epoch 1/1.. Train loss: 59.665.. Test loss: 54.353.. \n",
      "Epoch 1/1.. Train loss: 55.310.. Test loss: 54.231.. \n",
      "Epoch 1/1.. Train loss: 55.313.. Test loss: 54.541.. \n",
      "Epoch 1/1.. Train loss: 54.783.. Test loss: 55.342.. \n",
      "Epoch 1/1.. Train loss: 57.861.. Test loss: 54.910.. \n",
      "Epoch 1/1.. Train loss: 62.225.. Test loss: 54.497.. \n",
      "Epoch 1/1.. Train loss: 57.411.. Test loss: 54.373.. \n",
      "Epoch 1/1.. Train loss: 54.799.. Test loss: 54.822.. \n",
      "Epoch 1/1.. Train loss: 56.167.. Test loss: 54.743.. \n",
      "Epoch 1/1.. Train loss: 57.530.. Test loss: 55.851.. \n",
      "Epoch 1/1.. Train loss: 58.571.. Test loss: 55.532.. \n",
      "Epoch 1/1.. Train loss: 55.275.. Test loss: 54.644.. \n",
      "Epoch 1/1.. Train loss: 58.056.. Test loss: 56.156.. \n",
      "Epoch 1/1.. Train loss: 58.085.. Test loss: 56.581.. \n",
      "Epoch 1/1.. Train loss: 56.784.. Test loss: 55.296.. \n",
      "Epoch 1/1.. Train loss: 55.905.. Test loss: 54.284.. \n",
      "Epoch 1/1.. Train loss: 56.872.. Test loss: 55.165.. \n",
      "Epoch 1/1.. Train loss: 54.526.. Test loss: 56.224.. \n",
      "Epoch 1/1.. Train loss: 55.677.. Test loss: 56.405.. \n",
      "Epoch 1/1.. Train loss: 58.648.. Test loss: 54.616.. \n",
      "Epoch 1/1.. Train loss: 59.797.. Test loss: 54.799.. \n",
      "Epoch 1/1.. Train loss: 56.794.. Test loss: 56.590.. \n",
      "Epoch 1/1.. Train loss: 58.511.. Test loss: 54.589.. \n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 50\n",
    "train_losses, test_losses = [], []\n",
    "for epoch in range(epochs):\n",
    "    print(scheduler.get_lr())\n",
    "    scheduler.step()\n",
    "    print(scheduler.get_lr())\n",
    "    for inputs, labels in trainloader:\n",
    "        steps += 1\n",
    "        running_loss += forward_model_train(inputs, labels)\n",
    "        #torch.cuda.ipc_collect()\n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    test_loss += forward_model_val(inputs, labels)\n",
    "                    #torch.cuda.ipc_collect()\n",
    "                    \n",
    "            print(f\"Epoch {epoch + 1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss / print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss / len(testloader):.3f}.. \")\n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "torch.save(model, 'aerialmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.044489,
     "end_time": "2020-10-10T13:46:15.035318",
     "exception": false,
     "start_time": "2020-10-10T13:46:14.990829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 11200.039307,
   "end_time": "2020-10-10T13:46:16.580546",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-10T10:39:36.541239",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
